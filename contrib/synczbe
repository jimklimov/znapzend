#!/usr/bin/env bash

# bashisms: $RANDOM is used, and this:
set -o pipefail

# (C) 2020 - 2021 by Jim Klimov
# PoC for: https://github.com/oetiker/znapzend/issues/503

# Warning: no code support for now to manage rootfs datasets with children!

# Here we send ALL incremental snapshots to allow branching off destinations
# Those not made by znapzend will not be cleaned by policy after regular sync!

# Assumptions: the datasets we care about are similarly named and structured
# zoneroots or rootfs'es under one container directory on source and dest:

# Examples below are for the setup discussed in the issue; you'll certainly
# need to set your own, as in `SR=rpool/zones/z1/ROOT DEBUG=no ./synczbe` :)
[ -n "$SR" ] || \
{ SR="nvpool/zones/omni151018/ROOT"; echo "WARNING: Using default SR='$SR'" >&2 ; }
[ -n "$DRBASE" ] || \
{ DRBASE="backup-adata/snapshots"; echo "WARNING: Using default DRBASE='$DRBASE'" >&2 ; }
DR="$DRBASE/$SR"

[ -n "${ZFSLIST_REGEX-}" ] && { echo "WARNING: Filtering dataset name discovery by regex: '$ZFSLIST_REGEX'" >&2; } || ZFSLIST_REGEX=""
zfslist_filter() {
    # Process the stream from "zfs list ..." to pick only interesting patterns
    # Primarily aimed at rootfs support where several OSes (failsafes...) may
    # be installed and there are validly several history owners to consider.
    if [ -z "$ZFSLIST_REGEX" ] ; then cat; return; fi

    egrep "$ZFSLIST_REGEX"
}

# For rootfs SR=rpool/ROOT or similar.
# You can find the "SR" names for local zones by interpolating:
#  ...zone root mountpoints from the OS:
#  MPTZONEROOTS="`zoneadm list -cp | awk -F: '{print $4}' | egrep -v '^/$'`"
#    /zones/omni151018
#  ...and looking under znapzend configured source trees:
#  ZFSZONEROOTS="`zfs list -Ho name,mountpoint -t filesystem -r nvpool/zones | egrep '(/ROOT\s|\s/)'`"
#    nvpool/zones/lx5        /zones/lx5
#    nvpool/zones/omni151018 /zones/omni151018
#    nvpool/zones/omni151018/ROOT    legacy
# In example above, "lx5" is not a root of a currently configured/recognized
# local zone, and/or it is a brand with some different structure to handle.
# The "omni151018" is one to process with this script, finding the mountpoint
# in one line and confirming that this dataset has a /ROOT child in another.

# Neuter writes by default until we are ready
ZFSW="echo ###WOULD### :; zfs"
[ "$DEBUG" = no ] && ZFSW=zfs \
&& echo "WARNING: DEBUG=$DEBUG => zfs operations for changing pool data are ENABLED, be sure to NOT HAVE znapzend service RUNNING!" >&2 \
|| echo "WARNING: debug mode by default, zfs operations for changing pool data are DISABLED" >&2

case "$SR" in
    */ROOT) ;;
    */) echo "ERROR: SR should be a dataset name" >&2 ;;
    *)  echo "WARNING: SR='$SR' is not a dataset name ending with '/ROOT', you might want to revise that (press Ctrl+C to abort now)" >&2
        sleep 5
        ;;
esac

# For portable regexing
WSCHAR="`printf ' \t'`"

DR_ZONED_SOURCE=""
DR_ZONED_VALUE="`zfs get -Ho value -s local zoned "$DR"`" && [ -n "$DR_ZONED_VALUE" ] && DR_ZONED_SOURCE="local"
if [ -z "$DR_ZONED_SOURCE" ]; then
    DR_ZONED_VALUE="`zfs get -Ho value zoned "$DR"`"
    DR_ZONED_SOURCE="`zfs get -Ho source zoned "$DR"`"
fi
DR_ZONED_DISARMED=false

DR_ZBE=""
DR_ZBE_ZONED_SOURCE=""
DR_ZBE_ZONED_VALUE=""
DR_ZBE_ZONED_DISARMED=false

optionalDisarmDestZonedProp() {
    DR_ZBE_ZONED_DISARMED=false
    DR_ZBE_ZONED_VALUE="`zfs get -Ho value -s local zoned "$DR_ZBE"`" && [ -n "$DR_ZBE_ZONED_VALUE" ] && DR_ZBE_ZONED_SOURCE="local"
    if [ -z "$DR_ZBE_ZONED_SOURCE" ]; then
        DR_ZBE_ZONED_VALUE="`zfs get -Ho value zoned "$DR_ZBE"`"
        DR_ZBE_ZONED_SOURCE="`zfs get -Ho source zoned "$DR_ZBE"`"
    fi

    if [ "$DR_ZBE_ZONED_VALUE" = on ]; then

        if ! $DR_ZONED_DISARMED && [ "$DR_ZONED_VALUE" = on ]; then
            DR_ZONED_DISARMED=true
            echo "Disarming zoned property on '$DR' ..." >&2
            $ZFSW set zoned=off "$DR"

            # Re-evaluate whether we need to tweak each
            # ZBE, or changing its parent helped already
            DR_ZBE_ZONED_VALUE="`zfs get -Ho value -s local zoned "$DR_ZBE"`" && [ -n "$DR_ZBE_ZONED_VALUE" ] && DR_ZBE_ZONED_SOURCE="local"
            if [ -z "$DR_ZBE_ZONED_SOURCE" ]; then
                DR_ZBE_ZONED_VALUE="`zfs get -Ho value zoned "$DR_ZBE"`"
                DR_ZBE_ZONED_SOURCE="`zfs get -Ho source zoned "$DR_ZBE"`"
            fi
        fi

        if [ "$DR_ZBE_ZONED_VALUE" = on ]; then
            echo "Disarming zoned property on '$DR_ZBE' ..." >&2
            DR_ZBE_ZONED_DISARMED=true
            $ZFSW set zoned=off "$DR_ZBE"
        fi
    fi
}

exit_trap() {
    EXIT_RES=$?

    trap true 2 # ignore break for now

    $DR_ZONED_DISARMED && \
    echo "Restoring zoned property on $DR to $DR_ZONED_SOURCE $DR_ZONED_VALUE ..." >&2 && \
    case "$DR_ZONED_SOURCE" in
        local)
            $ZFSW set zoned="$DR_ZONED_VALUE" "$DR" ;;
        inherited)
            $ZFSW inherit set zoned "$DR" ;;
    esac

    $DR_ZBE_ZONED_DISARMED && \
    [ -n "$DR_ZBE" -a -n "$DR_ZBE_ZONED_SOURCE" -a -n "$DR_ZONED_VALUE" ] && \
    echo "Restoring zoned property on $DR_ZBE to $DR_ZBE_ZONED_SOURCE $DR_ZBE_ZONED_VALUE ..." >&2 && \
    case "$DR_ZBE_ZONED_SOURCE" in
        local)
            $ZFSW set zoned="$DR_ZBE_ZONED_VALUE" "$DR_ZBE"{,.bak} ;;
        inherited)
            $ZFSW inherit set zoned "$DR_ZBE"{,.bak} ;;
    esac

    trap - 2

    exit $EXIT_RES
}

trap "exit_trap" 0 1 2 3 15

# First phase:
# 1a) find latest available common snap in history owner on older dst (children
#     included) and same-named snapshot (with children) on newest src.
# 1b) zfs clone that into same relative name(s) on dst as newest src
# 1c) zfs promote all those clones on dst
# 1d) Replicate incrementally from that last common point to current tip
#     (note `zfs send -R -I ...` is recursive)

# e.g. zbe-30 is last history owner on backup, zbe-60 on source
# clones on source are branches of zbe-60, clones on dst between
# zbe-31 and zbe-59 are standalone by znapzend and own their histories =>
#   zfs list -d1 -tfilesystem -o name,origin -r {backup-adata/snapshots/,}nvpool/zones/omni151018/ROOT
### ^^^ Find and iterate rootfs/zbe children to find the recursively common snap between src and dst
#   zfs clone backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-30@2019-01-29-09:14:13 backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-60
#   zfs promote backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-60
#   zfs send -R -I nvpool/zones/omni151018/ROOT/zbe-60@{2019-01-29-09:14:13,2020-08-09-19:22:53} | mbuffer -m 128M | zfs recv -vue backup-adata/snapshots/nvpool/zones/omni151018/ROOT

# TODO: check if there are child datasets under ZBEs or rootfs'es
# and for now bail as unsupported (to develop)

# TODO also detect if the current src and dst are already in sync
# (same name, same tip; presume or check same intermediate snaps)
# and then skip phase 1 quickly.
echo "Phase 1: Make newest history owners same-named (and with same incremental snaps) on src and dst" >&2
SNO="`zfs list -Honame -d1 -tfilesystem,volume -screation -o name,origin -r "$SR" | zfslist_filter`"
DNO="`zfs list -Honame -d1 -tfilesystem,volume -screation -o name,origin -r "$DR" | zfslist_filter`"

STIPS="`echo "$SNO" | grep '/ROOT/' | egrep '\-$' | awk '{print $1}'`"
DTIPS="`echo "$DNO" | grep '/ROOT/' | egrep '\-$' | awk '{print $1}'`"
NSTIPS="`echo "$STIPS" | egrep -v '^$' | wc -l`"
NDTIPS="`echo "$DTIPS" | egrep -v '^$' | wc -l`"
echo "Phase 1: Discovered $NSTIPS source dataset tips (history owners):"; echo "$STIPS"
echo "Phase 1: Discovered $NDTIPS destination dataset tips (history owners):"; echo "$DTIPS"
if [ "$NSTIPS" = 1 ] && [ "$NDTIPS" = 1 ] ; then
    # ASSUME these come from same history
    SZ="`basename "$STIPS"`" # tip zbe name on src
    DZ="`basename "$DTIPS"`" # tip zbe name on dst
    if [ "$SZ" = "$DZ" -a -n "$SZ" ]; then
        echo "Phase 1: skipped clone/promote: Newest history owners are already same-named on src and dst" >&2
    else
        echo "Phase 1: Clone and promote destination tip dataset"

        # Check that src tip dataset name (SZ) does not yet exist on dst:
        if echo "$DNO" | awk '{print $1}' | egrep "/${SZ}"'$' ; then
            # Let user rectify this
            echo "Phase 1 fail: Dataset $SZ already exists under $DR (and is not a tip?)" >&2
            exit 1
        fi

        # Look at dst tip (DZ) dataset name in source tree
        # to see its origin snapshot name in history of SZ
        # (also check if it is in that direct history at all).
        # If all is ok, we would clone the existing (older)
        # destination dataset DZ snapshot found below into
        # a new destination dataset SZ, and then promote it.
        #
        # Filter logic: look at names+origins of src ZBEs,
        # and pick the (one) entry with DZ as the name,
        # and print its origin (snap with @ or '-' if a tip)
        # and only select variants where such source DZ is
        # a direct clone of SZ history owner. The resulting
        # DZO is a complete snapshot name; short is made below.
        # TODO: Recurse for other inheritance situations.
        DZO="`echo "${SNO}" | while read D O ; do case "$D" in */"${DZ}") echo "$O";; esac; done | grep "/${SZ}@"`" || DZO=""
        if [ -z "$DZO" ]; then
            # Let user rectify this
            echo "Phase 1 fail: Dataset $DZ under $SR does not exist or is not a clone of $SZ history owner" >&2
            exit 1
        fi

        # Get snap name: source DZ is tracked as clone of SZ@DZO_SNAP
        DZO_SNAP="`echo "$DZO" | sed 's,^[^@]*@,,'`"

        echo "Phase 1: under dst $DR, clone ${DZ}@${DZO_SNAP} as ${SZ} and promote it" >&2
        echo "(in the end, ${SZ}@${DZO_SNAP} should be origin of ${DZ} on dst same as on src)" >&2

        DR_ZBE="$DR/$DZ"
        optionalDisarmDestZonedProp

        $ZFSW clone "${DR}/${DZ}@${DZO_SNAP}" "${DR}/${SZ}" \
        && $ZFSW promote "${DR}/${SZ}" \
        || { echo "Phase 1 fail: could not clone/promote" >&2; exit 1; }

        if $DR_ZBE_ZONED_DISARMED ; then
            echo "Restoring zoned property on $DR/$DZ ..." >&2
            $ZFSW inherit zoned "$DR/$DZ"
            echo "Restoring zoned property on $DR/$SZ ..." >&2
            $ZFSW inherit zoned "$DR/$SZ"
            DR_ZBE_ZONED_DISARMED=false
            DR_ZBE=""
        fi
    fi

    if [ ! -n "$SZ" ] || [ ! -n "$DR" ] || [ ! -n "$SR" ]; then
        echo "Phase 1 fail: could not find some dataset name to clone/promote" >&2
        exit 1
    fi

    # Re-verify stuff, we could be in DEBUG mode and not actually change the destination
    echo "Phase 1: Check if we need to sync snaps of $SZ history owner on src and dst, and then do so"
    LD="`zfs list -d1 -Honame -tsnapshot -screation -r "${DR}/${SZ}" | zfslist_filter | tail -1`" || LD="" # latest on dst
    LS="`zfs list -d1 -Honame -tsnapshot -screation -r "${SR}/${SZ}" | zfslist_filter | tail -1`" || LS="" # latest on src

    if [ -z "$LD" ] || [ -z "$LS" ] ; then
        echo "Phase 1 fail: could not find some snapshots on history owner dataset $SZ under both src $SR and dst $DR" >&2
        exit 1
    fi

    # Derive short snap tags:
    LDS="`echo "$LD" | sed 's,^[^@]*@,,'`"
    LSS="`echo "$LS" | sed 's,^[^@]*@,,'`"

    if [ -z "$LDS" ] || [ -z "$LSS" ] ; then
        echo "Phase 1 fail: could not find some snapshot names on history owner dataset $SZ under both src $SR and dst $DR" >&2
        exit 1
    fi

    if [ "$LDS" = "$LSS" ]; then
        echo "Phase 1: History owner $SZ is already up to date (per latest snapshot name)" >&2
    else
        echo "Phase 1: Refresh history owner $SZ => $LD .. $LS" >&2

        # Update from older snapname known on backup destination
        # to newer snapname known on source.
        echo ":; time zfs send -R -I '$SR/$SZ@$LDS' '$SR/$SZ@$LSS' | mbuffer -m 128M | zfs recv -vue '$DR'"
        time zfs send -Lce -RI "$SR/$SZ@$LDS" "$SR/$SZ@$LSS" | mbuffer -m 128M | $ZFSW recv -vue "$DR" || exit
    fi

else
    # * If NDTIPS==0, there may be no datasets on dest (just too new), or
    #   ones present are all clones made from origins in another zfs tree
    # * If NDTIPS==1, we can probably find which of STIPS is its progenitor
    # * Otherwise probably at some point backups were made that autoCreated
    #   (by znapzend default ability) the destinations from scratch and not
    #   as zfs clones
    # * Generally otherwise, e.g. many unrelated rootfs'es of different OSes
    #   (probably not a consideration for ZBE), need to be smart to map them
    echo "TODO: Phase 1: Do not know how to arrange current layout (expected one history on source and one on destination)" >&2
    echo "You can select the destination history owner you would like to use"
    echo "(probably one with most child datasets branched off) e.g. 'zbe-XX'"
    echo "below, and move others to a separate ZFS tree, e.g.:"
    echo ':; XX=123'
    echo ":; zfs create -p '${DR}.bak'"
    echo ":; zfs set zoned=off '${DR}' '${DR}.bak'"
    echo ':; TABCHAR="`printf '"'"'\\t'"'"'`"'
    echo ":; zfs list -Honame,origin -r '${DR}' | grep /ROOT/ | egrep -v \"/zbe-\$XX[@ \$TABCHAR]\" |"
    echo '   while read D O ; do zfs rename "$D" "`echo "$D" | sed "s,/ROOT/,/ROOT.bak/,"`" & done ; wait; sync'
    echo ":; zfs set zoned=on '${DR}' '${DR}.bak'"
    echo "Hopefully this would also avoid ZFS automatically receiving newly"
    echo "backed up clones as increments over a wrong compatible dataset tree."
    echo "You can move those back later, if the clones recreated in correct"
    echo "tree during next phases do not cover this."
    if [ "$NSTIPS" = 1 ]; then
        echo "NOTE: Will sleep a bit for the above to sink in, and fall through to try and clean up destination history owners"
        sleep 10
    else
        echo "NOTE: If you validly have several rootfs naming patterns, consider"
        echo "constraining the choice with: export ZFSLIST_REGEX='...'"
        exit 1
    fi
fi

# Phase 2: rewrite existing standalone backups
echo "=== Gathering data for Phase 2 over '$SR' => '$DR' resync ..." >&2

# 2a) Rediscover current layout:
# Note that sorting is magic :) e.g. by creation time on destination, you see
# the replicated tip first and clones made from it by `zfs recv` appeared later
# while on source they would be more ordered (if source was not replicated too).
SNO="`zfs list -Honame -d1 -tfilesystem,volume -screation -o name,origin -r "$SR" | zfslist_filter`"
DNO="`zfs list -Honame -d1 -tfilesystem,volume -screation -o name,origin -r "$DR" | zfslist_filter`"

# 2b) Find history owners on destination (rootfs/zbe names whom would we rewrite if we still can?)
# Note we ignore all lines that list a snapshot "@" here, although some histories can be owned by different tips:
#   backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-27      backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-60@2018-10-17-21:49:25
#   backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-28      backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-30@2019-02-13-01:22:08 ### <<< zbe-30@...
#   backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-29      backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-60@2019-01-29-09:14:13
#   backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-30      backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-60@2019-01-29-09:14:13
#   backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-31      -
# This can be due to a miss in choice of latest common snapshot to clone and
# replicate that is not the latest branch on destination, or independent trees
# like rootfs with distro and failsafe-boot env, or other distros in same rpool.
# Might go over such later, filtering by "${newestbe}\@" ...

DZ="`echo "$DNO" | grep -v @ | awk '{print $1}' | awk -F/ '{print $NF}' | grep -v ROOT`"

# 2c) Find all histories we can rebase, and their span of snapshots
# from branching point to tip of the dataset:
#   zbe-31 => nvpool/zones/omni151018/ROOT/zbe-60@2019-10-04-12:28:11 .. nvpool/zones/omni151018/ROOT/zbe-31@znapzend-auto-2020-08-08T00:38:11Z
#   zbe-32 => nvpool/zones/omni151018/ROOT/zbe-60@2019-11-15-14:33:16 .. nvpool/zones/omni151018/ROOT/zbe-32@znapzend-auto-2020-08-08T00:38:11Z
#   === zbe-33 not in source
#   zbe-34 => nvpool/zones/omni151018/ROOT/zbe-60@2019-12-19-09:10:31 .. nvpool/zones/omni151018/ROOT/zbe-34@znapzend-auto-2020-08-08T00:38:11Z
# ...
#   zbe-58 => nvpool/zones/omni151018/ROOT/zbe-60@2020-06-22-16:58:55 .. nvpool/zones/omni151018/ROOT/zbe-58@znapzend-auto-2020-08-08T00:38:11Z
#   zbe-59 => nvpool/zones/omni151018/ROOT/zbe-60@2020-08-09-19:22:53 .. 
#   zbe-60 => - .. nvpool/zones/omni151018/ROOT/zbe-60@2020-08-09-19:22:53
# No big surprise with znapzend involved that newest snapnames all look the same
# For zbe-59 - it was recently branched on source from zbe-60 (in fact vice
# versa, but then `zfs promote` reshuffled them) and does not yet have snapshots
# of its own. zbe-60 is the current history owner.

RESFINAL=0
COUNTOK=0
COUNTFAIL=0
echo "=== Processing collected dataset details..." >&2
for Z in $DZ ; do
    RES=0
    ZL="`echo "$SNO" | egrep "^${SR}/${Z}\s"`" || { echo "!!! SKIP: $Z not in source" >&2 ; continue ; }
    O="`echo "$ZL" | awk '{print $NF}'`" # origin on src
    L="`zfs list -d1 -Honame -tsnapshot -screation -r "${SR}/${Z}" | zfslist_filter | tail -1`" || continue # latest on src
    echo "$Z => $O .. $L" >&2
    # We got listing for 3b up here

    # NOTE: For rootfs with children, check that all children on src and dst
    # are present and have in common the same-named snapshots, so a later
    # replication stream can continue from a single snapshot name of the parent
    # dataset (rootfs). This is a highly likely condition ensured by `beadm`
    # but may be lacking on dataset subtrees cloned and promoted on source
    # pool by other means.

    if [ -z "$O" -o "$O" = "-" ] ; then
        echo "=== SKIP a history owner: $Z" >&2
        continue
    fi

    if [ "$DEBUG" = quick ]; then
        if [ -z "$L" ] ; then
            echo "=== $Z is a recent clone (has no snaps yet on src)" >&2
        fi
        continue
    fi


    # OS is snapname, but useful is OSD with ZBE/rootfs name relative to ROOT/
    #OS="`echo "$O" | sed 's/^.*@//'`"
    OSD="`echo "$O" | sed "s@^${SR}/@@"`"

    echo "=== Move away the destination to back it up for now: '$DR/$Z' => '$DR/$Z.bak'" >&2
    DR_ZBE="$DR/$Z"
    optionalDisarmDestZonedProp
    $ZFSW rename "$DR/$Z" "$DR/$Z.bak"

    if $DR_ZBE_ZONED_DISARMED ; then
        # For a backup copy, normally we do not want to restore
        # original "zoned" value, just inherit one (and that
        # eventually stabilizes as "off" to avoid automounting)
        $ZFSW inherit zoned "$DR/$Z.bak"
        DR_ZBE_ZONED_DISARMED=false
        DR_ZBE=""
    fi

    #echo "=== Make new destination clone: '$DR/$OSD' => '$DR/$Z'" >&2
    #$ZFSW clone "$DR/$OSD" "$DR/$Z"
    # UGH: manually making clone and send+recv fails with:
    #   cannot receive new filesystem stream: destination 'backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-31' is a clone
    #   must destroy it to overwrite it
    # but having no named destination and sufficient source snapshot automakes the dest

    if [ -z "$L" ] ; then
        # create snap, send it as the increment to have ZFS create clone the way it likes
        # PoC NOTE: Assumes GNU date or compatible with +%s to add uniqueness to the snapname string
        L="$SR/$Z@auto-firstsnap-`date -u +%s || date -u | tr '[ ,:@_\.]' '-'`-$$-$RANDOM"
        echo "=== SNAP a recent clone (has no snaps yet on src): $Z => make '$L' to sync" >&2
        $ZFSW snapshot -r "$L"
        #continue
    fi

    #LS="`echo "$L" | sed 's/^.*@//'`"

    # NOTE: NO LONGER RELEVANT: (was: For rootfs with children, have all children clones prepared before zfs send/recv)

    echo "=== Update the new destination + create dst clone: increment '$O' => '$L', write into autotarget under '$DR' (overwrite with -F if needed?)" >&2
    echo ":; time zfs send -R -I '$O' '$L' | mbuffer -m 128M | zfs recv -vue '$DR'"
    time zfs send -R -I "$O" "$L" | mbuffer -m 128M | $ZFSW recv -vue "$DR" ; RES=$?
    #zfs send -R -I nvpool/zones/omni151018/ROOT/zbe-60@{2019-01-29-09:14:13,2020-08-09-19:22:53} | mbuffer -m 128M | $ZFSW recv -vue backup-adata/snapshots/nvpool/zones/omni151018/ROOT
    #  found clone origin backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-60@2019-10-04-12:28:11
    #  receiving incremental stream of nvpool/zones/omni151018/ROOT/zbe-31@znapzend-auto-2019-10-11T17:30:00Z into backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-31@znapzend-auto-2019-10-11T17:30:00Z
    #  in @  0.0 KiB/s, out @  0.0 KiB/s,  316 KiB total, buffer   1% full
    #  received 312B stream in 103 seconds (3B/sec)
    #  receiving incremental stream of nvpool/zones/omni151018/ROOT/zbe-31@znapzend-auto-2019-10-12T00:00:00Z into backup-adata/snapshots/nvpool/zones/omni151018/ROOT/zbe-31@znapzend-auto-2019-10-12T00:00:00Z
    #  in @  0.0 KiB/s, out @  0.0 KiB/s,  316 KiB total, buffer   1% full
    #  received 312B stream in 6 seconds (52B/sec)

    echo "=== DONE ($RES) with $Z"; echo ""
    if [ "$RES" = 0 ] ; then
        COUNTOK=$(($COUNTOK+1))
    else
        RESFINAL="$RES"
        COUNTFAIL=$(($COUNTFAIL+1))
    fi
done

echo "Phase 3: Pass over the current dataset layout and see if there are any datasets on source that are not on dest, remove ZBE-N.bak on dest if unneeded anymore" >&2
SNO="`zfs list -Honame -d1 -tfilesystem,volume -screation -o name,origin -r "$SR" | zfslist_filter | grep '/ROOT/'`"
DNO="`zfs list -Honame -d1 -tfilesystem,volume -screation -o name,origin -r "$DR" | zfslist_filter | grep '/ROOT/'`"

# Names of sub-datasets on src and dst:
SN="`echo "$SNO" | awk '{print $1}' | awk -F/ '{print $NF}' | sort -n`"
DN="`echo "$DNO" | awk '{print $1}' | awk -F/ '{print $NF}' | sort -n`"
DIFF="`diff -bu <(echo "$DN") <(echo "$SN") | egrep '^[-+]' | egrep -v '^(\-\-\-|\+\+\+)'`"
ONLY_SRC="`echo "$DIFF" | egrep '^\+' | sed 's,^\+,,'`"
ONLY_DST="`echo "$DIFF" | egrep '^\-' | sed 's,^\-,,'`"
if [ -n "$ONLY_DST" ]; then
    echo "FYI: Sub-dataset names only present on backup destination (original obsoleted and removed?): " $ONLY_DST
fi
if [ -n "$ONLY_SRC" ]; then
    echo "Sub-dataset names only present on original source (cloning and backup needed): " $ONLY_SRC
    # TODO: Send datasets grouped by presence of their cloning origin
    # on target pool. The first (and often only) such group is based
    # on the common "history owner" that Phase 1 hopefully ensured
    # and updated so it has all needed intermediate snapshots.

    OLD_SNO=""
    while [ -n "$SNO" ] && [ "$SNO" != "$OLD_SNO" ]; do
        OLD_SNO="$SNO"
        STIPS="`echo "$SNO" | egrep '\-$' | awk '{print $1}'`"
        #DTIPS="`echo "$DNO" | egrep '\-$' | awk '{print $1}'`"

        if [ -z "$STIPS" ]; then
            # We ran out of datasets that are history owners and are
            # origins for clones, but some not-synced clones remain.
            # Select remaining origin datasets, most populat first:
            STIPS="`echo "$SNO" | awk '{print $2}' | sed 's,@.*$,,' | sort | uniq -c | sort -nr | awk '{print $2}'`"
            echo "Phase 3: Looking at origin datasets that are not history owners:"
            echo "$STIPS"
        fi

        for STIP in $STIPS ; do
            SZ="`basename "$STIP"`" # tip zbe name on src - origin for others
            # No zfslist_filter here, we already look at filtered names
            zfs list "$DR/$SZ" \
            || { echo "Phase 3: history owner $SZ is not present (yet?) under dst $DR" >&2 ; continue; }

            LIST="`echo "$SNO" | grep "/${SZ}@"`" || LIST=""
            if [ -n "$LIST" ]; then
                echo "Phase 3: Processing datasets with origin $STIP ($SZ)..."
                # Read LIST as dataset (full name under SR) + origin fields:
                while read D O ; do
                    SKIP=true
                    for Z in $ONLY_SRC; do
                        case "$D" in
                            */"$Z") SKIP=false; break;;
                        esac
                    done
                    if $SKIP ; then
                        echo "Phase 3: skip $D because it is not among datasets only on src" >&2
                        continue
                    fi

                    LS="`zfs list -d1 -Honame -tsnapshot -screation -r "${D}" | zfslist_filter | tail -1`" || LS="" # latest on src
                    # Derive short snap tags:
                    LSS="`echo "$LS" | sed 's,^[^@]*@,,'`"
                    if [ -z "$LS" ] || [ -z "$LSS" ]; then
                        echo "Phase 3 partial fail: could not find some snapshots on leaf dataset $D under src $SR" >&2
                        COUNTFAIL=$(($COUNTFAIL+1))
                        continue
                    fi

                    echo "Send to clone+update `basename "$D"` => $O .. $D@$LSS"

                    RES=0
                    echo ":; time zfs send -R -I '$O' '$D@$LSS' | mbuffer -m 128M | zfs recv -vue '$DR'"
                    time zfs send -Lce -RI "$O" "$D@$LSS" | mbuffer -m 128M | $ZFSW recv -vue "$DR" || RES=$?

                    echo "=== DONE ($RES) with $D"; echo ""
                    if [ "$RES" = 0 ] ; then
                        COUNTOK=$(($COUNTOK+1))
                    else
                        RESFINAL="$RES"
                        COUNTFAIL=$(($COUNTFAIL+1))
                    fi
                done <<EOF
$LIST
EOF

                SNO="`echo "$SNO" | egrep -v "(/${SZ}@|\-\$)"`"
            fi
        done ### for STIP

        if [ -n "$SNO" ] ; then
            echo "Phase 3: Remaining source name+origin entries to process:"
            echo "$SNO"
        fi
    done ### while SNO

    if [ -n "$SNO" ] ; then
        echo "WARNING: Phase 3 gave up on some datasets it could not sync, see remaining list above"
    fi
fi

echo "NOTE: Phase 3 should have completed well before re-enabling znapzend, so you do not lose intermediate snapshots that may be important for cloning!"

echo "Final result of $SR => $DR sync: $RESFINAL ($COUNTOK OK, $COUNTFAIL failed)" >&2
exit $RESFINAL
